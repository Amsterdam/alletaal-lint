name: Code Quality

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  lint-and-format:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"

    - name: Check code formatting with Black
      run: |
        black --check --diff src/ tests/

    - name: Check import sorting with isort
      run: |
        isort --check-only --diff src/ tests/

    - name: Lint with flake8
      run: |
        # Stop the build if there are Python syntax errors or undefined names
        flake8 src/ tests/ --count --select=E9,F63,F7,F82 --show-source --statistics

    - name: Type checking with mypy
      run: |
        mypy src/alletaal_lint/ --ignore-missing-imports --strict

  security-analysis:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"

    - name: Install security tools
      run: |
        python -m pip install --upgrade pip
        pip install bandit safety

    - name: Security analysis with Bandit
      run: |
        bandit -r src/ -f json -o bandit-report.json
        bandit -r src/

    - name: Dependency vulnerability check with Safety
      run: |
        safety check --json --output safety-report.json
        safety check

    - name: Upload security scan results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json

  documentation-check:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .

    - name: Check README links
      run: |
        pip install requests
        python -c "
        import re
        import requests
        
        with open('README.md', 'r') as f:
            content = f.read()
        
        # Find all markdown links
        links = re.findall(r'\[.*?\]\((https?://[^\)]+)\)', content)
        
        failed_links = []
        for link in links:
            try:
                response = requests.head(link, timeout=10, allow_redirects=True)
                if response.status_code >= 400:
                    failed_links.append((link, response.status_code))
            except Exception as e:
                failed_links.append((link, str(e)))
        
        if failed_links:
            print('Failed links:')
            for link, error in failed_links:
                print(f'  {link}: {error}')
            # Don't fail the build for external link issues
            print('Warning: Some external links failed, but continuing...')
        else:
            print('All links are accessible!')
        "

    - name: Validate package metadata
      run: |
        pip install twine
        python -m build
        twine check dist/*

  dependency-analysis:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"

    - name: Install package
      run: |
        python -m pip install --upgrade pip
        pip install -e .

    - name: Check dependency tree
      run: |
        pip install pipdeptree
        pipdeptree

    - name: Check for dependency conflicts
      run: |
        pip check

  performance-analysis:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"

    - name: Install package and profiling tools
      run: |
        python -m pip install --upgrade pip
        pip install -e .
        pip install line-profiler memory-profiler

    - name: Download spaCy model
      run: |
        python -m spacy download nl_core_news_sm

    - name: Profile memory usage
      run: |
        python -c "
        from memory_profiler import profile
        from alletaal_lint import Document, Sentence
        
        @profile
        def test_memory():
            # Test sentence processing
            sentence = Sentence('Dit is een test zin voor memory profiling.')
            score = sentence.calculate_lint_score()
            
            # Test document processing
            doc = Document('Dit is een test document. Het bevat meerdere zinnen. Dit is de derde zin.')
            doc_score = doc.calculate_lint_score()
            
            return score, doc_score
        
        test_memory()
        "

    - name: Performance benchmark
      run: |
        python -c "
        import time
        import statistics
        from alletaal_lint import Document, Sentence
        
        # Benchmark sentence processing
        times = []
        for i in range(50):
            start = time.time()
            sentence = Sentence('Dit is een test zin voor performance benchmark.')
            score = sentence.calculate_lint_score()
            end = time.time()
            times.append(end - start)
        
        avg_time = statistics.mean(times)
        std_dev = statistics.stdev(times)
        
        print(f'Sentence processing:')
        print(f'  Average time: {avg_time*1000:.2f}ms')
        print(f'  Standard deviation: {std_dev*1000:.2f}ms')
        print(f'  Min time: {min(times)*1000:.2f}ms')
        print(f'  Max time: {max(times)*1000:.2f}ms')
        
        # Benchmark document processing
        doc_times = []
        test_text = 'Dit is een test document. ' * 10
        
        for i in range(20):
            start = time.time()
            doc = Document(test_text)
            score = doc.calculate_lint_score()
            end = time.time()
            doc_times.append(end - start)
        
        doc_avg = statistics.mean(doc_times)
        doc_std = statistics.stdev(doc_times)
        
        print(f'\\nDocument processing ({len(test_text)} chars):')
        print(f'  Average time: {doc_avg*1000:.2f}ms')
        print(f'  Standard deviation: {doc_std*1000:.2f}ms')
        print(f'  Min time: {min(doc_times)*1000:.2f}ms')
        print(f'  Max time: {max(doc_times)*1000:.2f}ms')
        
        # Performance assertions
        assert avg_time < 1.5, f'Sentence processing too slow: {avg_time}s'
        assert doc_avg < 3.0, f'Document processing too slow: {doc_avg}s'
        
        print('\\nPerformance benchmarks passed!')
        "

  api-schema-validation:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"

    - name: Install package
      run: |
        python -m pip install --upgrade pip
        pip install -e .

    - name: Download spaCy model
      run: |
        python -m spacy download nl_core_news_sm

    - name: Validate API schema
      run: |
        python -c "
        from alletaal_lint.api import create_app
        import json
        
        app = create_app()
        
        # Get OpenAPI schema
        openapi_schema = app.openapi()
        
        # Basic schema validation
        assert 'openapi' in openapi_schema
        assert 'info' in openapi_schema
        assert 'paths' in openapi_schema
        
        # Check required endpoints
        required_endpoints = [
            '/score-sentence',
            '/score-document', 
            '/analyze-document',
            '/health',
            '/methodology'
        ]
        
        for endpoint in required_endpoints:
            assert endpoint in openapi_schema['paths'], f'Missing endpoint: {endpoint}'
        
        # Check response schemas
        for path, methods in openapi_schema['paths'].items():
            for method, details in methods.items():
                if 'responses' in details:
                    assert '200' in details['responses'], f'Missing 200 response for {method} {path}'
        
        print('API schema validation passed!')
        print(f'Found {len(openapi_schema[\"paths\"])} endpoints')
        "

  changelog-check:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Check if changelog needs update
      run: |
        # Check if code changes require changelog update
        changed_files=$(git diff --name-only origin/main...HEAD)
        
        code_changed=false
        if echo "$changed_files" | grep -E '^src/|^tests/|^pyproject.toml$' > /dev/null; then
            code_changed=true
        fi
        
        changelog_updated=false
        if echo "$changed_files" | grep -E '^CHANGELOG.md$|^HISTORY.md$' > /dev/null; then
            changelog_updated=true
        fi
        
        if [ "$code_changed" = true ] && [ "$changelog_updated" = false ]; then
            echo "::warning::Code changes detected but no changelog update found"
            echo "Consider updating CHANGELOG.md or adding release notes"
        else
            echo "Changelog check passed"
        fi